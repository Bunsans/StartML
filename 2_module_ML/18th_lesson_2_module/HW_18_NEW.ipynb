{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x9TbZ0UyyF0I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCHwqIE8yF0M"
   },
   "source": [
    "### Загрузим датасет с машинами. Цель - верно восстанавливать для каждой из них цену продажи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vHohclJJyF0O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>2007</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>2007</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>2017</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year  selling_price  km_driven    fuel  \\\n",
       "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
       "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
       "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
       "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
       "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner  \n",
       "0  Individual       Manual   First Owner  \n",
       "1  Individual       Manual   First Owner  \n",
       "2  Individual       Manual   First Owner  \n",
       "3  Individual       Manual   First Owner  \n",
       "4  Individual       Manual  Second Owner  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('autos.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_48JHObiyF0P"
   },
   "outputs": [],
   "source": [
    "### Колонка с тергетом - \"selling price\"\n",
    "\n",
    "X = data.drop(\"selling_price\", axis=1)\n",
    "y = data[\"selling_price\"]\n",
    "\n",
    "### Будем замерять MSLE!\n",
    "### Поэтому прологарифмируем таргет\n",
    "### А после оптимизируем MSE\n",
    "\n",
    "y = y.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-7qoCjH_yF0Q"
   },
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн и тест!\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2Cawl_lyF0Q"
   },
   "source": [
    "__Задание__ \n",
    "\n",
    "Реализуйте свой MeanTargetEncoder с добавленем некоторого шума!\n",
    "\n",
    "Однажды в лекционном материале, обсуждая счетчики, мы говорили с вами о том, что из-за них модели могут переобучаться. Один из способов бороться с этим - валидировать расчеты среднего таргета (стратегия отложенной выборки / расчеты на кросс-валидации). Но есть еще проще!\n",
    "\n",
    "Можно просто к значению счетчика добавить случайный шум (зашумить данные)!\n",
    "\n",
    "Напомним, что рассчитываться новые признаки должны по такой формуле:\n",
    "\n",
    "$$\n",
    "g_j = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}{l} + C * \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Пусть шум будет случайной величиной из нормального стандартного распределения, то есть $\\epsilon \\sim N(0, 1) $, а $ C = 0.006$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeVJ1WRbyF0R"
   },
   "source": [
    "Создавая свой класс-трансформер, наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`. Трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. Ваш трансформер должен принимать при инициализации список из категориальных признаков и список из числовых признаков. \n",
    "\n",
    "Если для какого-то признака в тестовой выборке отсутствует значение, трансформер должен поставить там 0.\n",
    "\n",
    "На выходе должен получиться датасет того же размера с измененными категориальными признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvgr07YgVpkR"
   },
   "source": [
    "Класс MeanTargetEncoderNoise должен иметь следующую сигнатуру:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcM2Ax1CWBlY"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoderNoise(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical, numeric):              \n",
    "        ### Your code is here\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        ### Your code is here\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def transform(self, df):\n",
    "        ### Your code is here\n",
    "        \n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s8IjJMbViVS"
   },
   "source": [
    "Разделите колонки на вещественные и категориальные. Приведите все категориальные колонки к типу `object`.\n",
    "\n",
    "Далее применим наш кодировщик к `X_train, X_test`, так же как например мы применяем `StandardScaler`, чтобы проверить работоспособность нашего класса. Установите зерно датчика случайный чисел `np.random.seed(1)`.\n",
    "\n",
    "После того, как вы изменили обучающую и тестовую выборки, сохраните первые 10 строк полученного промежуточного датафрейма обучающей выборки (`X_train`) в файл в формате csv с сепаратором `;`. Не забудьте индекс. Отправьте полученный файл в форму ниже.\n",
    "\n",
    "Список колонок которые должны быть в файле для сдачи:\n",
    "```py\n",
    "cols = [\n",
    "    \"km_driven\",\n",
    "    \"name\",\n",
    "    \"year\",\n",
    "    \"fuel\",\n",
    "    \"seller_type\",\n",
    "    \"transmission\",\n",
    "    \"owner\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "942UEr0bV7yb"
   },
   "source": [
    "### Ваше решение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLSV8-OrWO6_"
   },
   "source": [
    "Разделение колонок на категориальные и числовые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jfENggauyF0S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>2007</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>2007</td>\n",
       "      <td>50000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>2017</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>2014</td>\n",
       "      <td>141000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year  km_driven    fuel seller_type transmission  \\\n",
       "0             Maruti 800 AC  2007      70000  Petrol  Individual       Manual   \n",
       "1  Maruti Wagon R LXI Minor  2007      50000  Petrol  Individual       Manual   \n",
       "2      Hyundai Verna 1.6 SX  2012     100000  Diesel  Individual       Manual   \n",
       "3    Datsun RediGO T Option  2017      46000  Petrol  Individual       Manual   \n",
       "4     Honda Amaze VX i-DTEC  2014     141000  Diesel  Individual       Manual   \n",
       "\n",
       "          owner  \n",
       "0   First Owner  \n",
       "1   First Owner  \n",
       "2   First Owner  \n",
       "3   First Owner  \n",
       "4  Second Owner  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = ['name', 'year', 'fuel', 'seller_type', 'transmission', 'owner']\n",
    "num_cols = ['km_driven']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vudi3wkzWToS"
   },
   "source": [
    "Реализация класса MeanTargetEncoderNoise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target']\n",
      "target\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.DataFrame({'A': ['A', 'A', 'B','B', 'C'],\n",
    "                  'B': [1, 2, 3, 4, 5],\n",
    "                  'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
    "df_2 = pd.DataFrame({'target': [1, 1, 2, 1, 2]})\n",
    "\n",
    "print(df_2.columns.values.tolist())\n",
    "\n",
    "y = df_2['target']\n",
    "pd.concat((df_1, y), axis=1)\n",
    "\n",
    "print(y.name)\n",
    "# print(df_1)\n",
    "# res = df_1.groupby('A')['B'].mean()\n",
    "# for cat in df_1.groupby('A')['B'].mean().index:\n",
    "#     res.loc[cat] += 1 * np.random.rand(1)[0]\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34189925938105514"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1007465627.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    for val in X_fit[cat].unique()\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "for cat in self.cat_name:\n",
    "            for val in X_fit[cat].unique()\n",
    "                self.mte_dict[val] = X_with_target[[cat, target_name]].groupby(val)[target_name].mean() + self.C_noise * np.random.rand(1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.74481176421648"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "038NwxXGyF0S"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoderNoise(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical, numeric):\n",
    "        \n",
    "        ### Your code is here\n",
    "        self.categorical = categorical\n",
    "        self.numeric = numeric\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        ### Your code is here\n",
    "        X_fit = X.copy()\n",
    "        y_fit = y.copy()\n",
    "        \n",
    "        self.target_name = y.name\n",
    "        \n",
    "        X_with_target = pd.concat((X_fit, y_fit), axis=1)\n",
    "        \n",
    "        # создаем и заполняем словарь название колонки: и датасет сгруппированных значений и mte + noise\n",
    "        self.C_noise = 0.006\n",
    "        self.mte_dict = dict()\n",
    "        \n",
    "        for col in  self.categorical:\n",
    "            self.mte_dict[col] = X_with_target.groupby(col)[self.target_name].mean()# + self.C_noise * np.random.normal()\n",
    "            for cat in self.mte_dict[col].index:\n",
    "                self.mte_dict[col].loc[cat] += self.C_noise * np.random.normal()            \n",
    "        return self\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \n",
    "        ### Your code is here\n",
    "        temp = df.copy()\n",
    "        \n",
    "        for col in self.categorical:\n",
    "            temp[col] = temp[col].map(self.mte_dict[col])\n",
    "            temp[col] = temp[col].fillna(0)\n",
    "            \n",
    "        \n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDt0igudWbUE"
   },
   "source": [
    "Проверка работы трансформера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      km_driven       name       year       fuel  seller_type  transmission  \\\n",
      "3294      50000  13.483692  13.436559  13.093756    12.615863     13.771135   \n",
      "2290      70000  12.117029  11.903115  12.453832    12.615863     13.771135   \n",
      "874       50000  12.310456  13.328864  12.453832    12.615863     12.639805   \n",
      "1907      92198  12.491443  13.042359  12.453832    13.152824     12.639805   \n",
      "3244       3240  12.390906  12.870886  12.453832    12.615863     12.639805   \n",
      "1089      10000  12.687432  13.436559  12.453832    13.152824     12.639805   \n",
      "3902      90000  11.698702  11.503504  12.453832    12.615863     12.639805   \n",
      "2215      79000  11.120678  11.503504  12.453832    12.615863     12.639805   \n",
      "3862      99700  13.172879  13.328864  13.093756    12.615863     12.639805   \n",
      "705      124000  13.004194  12.241213  13.093756    12.615863     12.639805   \n",
      "\n",
      "          owner  \n",
      "3294  12.977730  \n",
      "2290  12.977730  \n",
      "874   12.977730  \n",
      "1907  12.463313  \n",
      "3244  12.463313  \n",
      "1089  12.977730  \n",
      "3902  11.878390  \n",
      "2215  12.463313  \n",
      "3862  12.977730  \n",
      "705   12.463313  \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "transformer = MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)\n",
    "\n",
    "transformer.fit(X_train, y_train)\n",
    "\n",
    "train = transformer.transform(X_train)\n",
    "test = transformer.transform(X_test)\n",
    "\n",
    "cols = [\n",
    "    \"km_driven\",\n",
    "    \"name\",\n",
    "    \"year\",\n",
    "    \"fuel\",\n",
    "    \"seller_type\",\n",
    "    \"transmission\",\n",
    "    \"owner\"\n",
    "]\n",
    "print(train[cols].head(10))\n",
    "train[cols].head(10).to_csv('HW_18_res',sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9cgA3knyF0U"
   },
   "source": [
    "Обучите несколько деревьев, перебирая максимальную глубину алгоритма из списка `max_depth_list`, а остальные параметры оставьте дефолтными. Выведите лучшее значение гиперпараметра. Постройте график зависимости MSLE на тестовой выборке от значения гиперпараметра. Воспользуйтесь `Pipeline` без `GridSearch`. Проделайте то же самое с `min_samples_split`, `min_impurity_decrease`, `max_leaf_nodes`. (по 2б на каждый параметр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "VQCYxECdyF0U"
   },
   "outputs": [],
   "source": [
    "max_depth_list = [3, 5, 8, 12]\n",
    "min_samples_split_list = [10, 50, 100, 500]\n",
    "min_impurity_decrease_list = [0, 0.1, 0.15, 0.2]\n",
    "max_leaf_nodes_list = [100, 200, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_search(par_list, name_par):\n",
    "    res_list=[]\n",
    "    for par in par_list:\n",
    "        pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                     ('desicion_tree', DecisionTreeRegressor())])\n",
    "        par_dict = {f'desicion_tree__{name_par}' : par}\n",
    "        pipe.set_params(**par_dict)\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        depth_mse_list.append(round(mse(y_test, pipe.predict(X_test)), 3))\n",
    "    print(name_par, '\\n', res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "rRRl1cBayF0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.798, 1.441, 1.988, 1.984]\n",
      "[1.433, 1.438, 0.952, 0.808]\n",
      "[1.987, 0.519, 0.52, 0.52]\n",
      "[1.989, 1.989, 1.988]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "\n",
    "\n",
    "depth_mse_list = []\n",
    "for depth in max_depth_list:\n",
    "    pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                 ('desicion_tree', DecisionTreeRegressor(max_depth = depth))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    depth_mse_list.append(round(mse(y_test, pipe.predict(X_test)), 3))\n",
    "print(depth_mse_list)\n",
    "\n",
    "min_samples_split_mse_list = []\n",
    "for par in min_samples_split_list:\n",
    "    pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                 ('desicion_tree', DecisionTreeRegressor(min_samples_split = par))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    min_samples_split_mse_list.append(round(mse(y_test, pipe.predict(X_test)), 3))\n",
    "print(min_samples_split_mse_list)\n",
    "\n",
    "\n",
    "min_impurity_decrease_mse_list = []\n",
    "for par in min_impurity_decrease_list:\n",
    "    pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                 ('desicion_tree', DecisionTreeRegressor(min_impurity_decrease = par))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    min_impurity_decrease_mse_list.append(round(mse(y_test, pipe.predict(X_test)), 3))\n",
    "print(min_impurity_decrease_mse_list)\n",
    "\n",
    "\n",
    "max_leaf_nodes_mse_list = []\n",
    "for par in max_leaf_nodes_list:\n",
    "    pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                 ('desicion_tree', DecisionTreeRegressor(max_depth = par))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    max_leaf_nodes_mse_list.append(round(mse(y_test, pipe.predict(X_test)), 3))\n",
    "print(max_leaf_nodes_mse_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBkYnUa7yF0V"
   },
   "source": [
    "Подберите лучшую комбинацию параметров, используя `GridSearchCV` и набор массивов значений параметров из предыдущего задания. Для лучшей комбинации посчитайте MSLE на тестовой выборке. Получились ли лучшие параметры такими же, как если бы вы подбирали их по-отдельности при остальных гиперпараметрах по умолчанию (предыдущее задание)? (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "CnUu33ojyF0V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.18986):\n",
      "{'decision_tree__max_depth': 12, 'decision_tree__max_leaf_nodes': 200, 'decision_tree__min_impurity_decrease': 0.1, 'decision_tree__min_samples_split': 100}\n",
      "Качество лучшей модели на финальном тесте: 0.5200098587235228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"decision_tree__max_depth\": [3, 5, 8, 12],\n",
    "    \"decision_tree__min_samples_split\": [10, 50, 100, 500],\n",
    "    \"decision_tree__min_impurity_decrease\": [0, 0.1, 0.15, 0.2],\n",
    "    \"decision_tree__max_leaf_nodes\": [100, 200, 500]\n",
    "}\n",
    "np.random.seed(1)\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "pipe = Pipeline([(\"custom_transformer\", MeanTargetEncoderNoise(object_cols, num_cols)), \n",
    "                 ('decision_tree', DecisionTreeRegressor())])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameter (CV score={search.best_score_:.5f}):\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(f\"Качество лучшей модели на финальном тесте: {mse(y_test, search.predict(X_test))}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5201284981790175\n"
     ]
    }
   ],
   "source": [
    "pipe.set_params(**search.best_params_)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(mse(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
